{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing the challenge\n",
    "- Budgets for schools are huge, complex, and not standardizedHundreds of hours each year are spent manually labelling\n",
    "- Goal: Build a machine learning algorithm that can automate the process\n",
    "- Budget dataLine-item: \n",
    "    - \"Algebra books for 8th grade students\"\n",
    "- Labels: \"Textbooks\", \"Math\", \"Middle School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data\n",
    "Now it's time to check out the dataset! You'll use pandas (which has been pre-imported as pd) to load your data into a DataFrame and then do some Exploratory Data Analysis (EDA) of it.\n",
    "\n",
    "The training data is available as TrainingData.csv. Your first task is to load it into a DataFrame in the IPython Shell using pd.read_csv() along with the keyword argument index_col=0.\n",
    "\n",
    "Use methods such as .info(), .head(), and .tail() to explore the budget data and the properties of the features and labels.\n",
    "\n",
    "Some of the column names correspond to features - descriptions of the budget items - such as the Job_Title_Description column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee.\n",
    "\n",
    "Some columns correspond to the budget item labels you will be trying to predict with your model. For example, the Object_Type column describes whether the budget item is related classroom supplies, salary, travel expenses, etc.\n",
    "\n",
    "Use df.info() in the IPython Shell to answer the following questions:\n",
    "\n",
    "- How many rows are there in the training data?\n",
    "- How many columns are there in the training data?\n",
    "- How many non-null entries are in the Job_Title_Description column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "import pandas as pd\n",
    "df=pd.read_csv('TrainingData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Unnamed: 0            FTE         Total\n",
      "count  400277.000000  126071.000000  3.957220e+05\n",
      "mean   225186.018537       0.426794  1.310586e+04\n",
      "std    130025.142718       0.573576  3.682254e+05\n",
      "min         2.000000      -0.087551 -8.746631e+07\n",
      "25%    112601.000000       0.000792  7.379770e+01\n",
      "50%    225243.000000       0.130927  4.612300e+02\n",
      "75%    337722.000000       1.000000  3.652662e+03\n",
      "max    450340.000000      46.800000  1.297000e+08\n"
     ]
    }
   ],
   "source": [
    "# Print the summary statistics\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134338</td>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>50471.810</td>\n",
       "      <td>KINDERGARTEN</td>\n",
       "      <td>General Fund</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206341</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Non-Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RGN  GOB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNDESIGNATED</td>\n",
       "      <td>3477.860</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BUILDING IMPROVEMENT SERVICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>326408</td>\n",
       "      <td>Teacher Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TEACHER</td>\n",
       "      <td>62237.130</td>\n",
       "      <td>Instruction - Regular</td>\n",
       "      <td>General Purpose School</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364634</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UNALLOC BUDGETS/SCHOOLS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>22.300</td>\n",
       "      <td>GENERAL MIDDLE/JUNIOR HIGH SCH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47683</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>54.166</td>\n",
       "      <td>GENERAL HIGH SCHOOL EDUCATION</td>\n",
       "      <td>NaN</td>\n",
       "      <td>REGULAR INSTRUCTION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 Function          Use          Sharing  \\\n",
       "0      134338     Teacher Compensation  Instruction  School Reported   \n",
       "1      206341                 NO_LABEL     NO_LABEL         NO_LABEL   \n",
       "2      326408     Teacher Compensation  Instruction  School Reported   \n",
       "3      364634  Substitute Compensation  Instruction  School Reported   \n",
       "4       47683  Substitute Compensation  Instruction  School Reported   \n",
       "\n",
       "  Reporting Student_Type Position_Type               Object_Type     Pre_K  \\\n",
       "0    School     NO_LABEL       Teacher                  NO_LABEL  NO_LABEL   \n",
       "1  NO_LABEL     NO_LABEL      NO_LABEL                  NO_LABEL  NO_LABEL   \n",
       "2    School  Unspecified       Teacher  Base Salary/Compensation  Non PreK   \n",
       "3    School  Unspecified    Substitute                  Benefits  NO_LABEL   \n",
       "4    School  Unspecified       Teacher   Substitute Compensation  NO_LABEL   \n",
       "\n",
       "    Operating_Status  ... Sub_Object_Description Location_Description  FTE  \\\n",
       "0  PreK-12 Operating  ...                    NaN                  NaN  1.0   \n",
       "1      Non-Operating  ...                    NaN                  NaN  NaN   \n",
       "2  PreK-12 Operating  ...                    NaN                  NaN  1.0   \n",
       "3  PreK-12 Operating  ...                    NaN                  NaN  NaN   \n",
       "4  PreK-12 Operating  ...                    NaN                  NaN  NaN   \n",
       "\n",
       "      Function_Description Facility_or_Department              Position_Extra  \\\n",
       "0                      NaN                    NaN               KINDERGARTEN    \n",
       "1                 RGN  GOB                    NaN                UNDESIGNATED   \n",
       "2                      NaN                    NaN                     TEACHER   \n",
       "3  UNALLOC BUDGETS/SCHOOLS                    NaN  PROFESSIONAL-INSTRUCTIONAL   \n",
       "4              NON-PROJECT                    NaN  PROFESSIONAL-INSTRUCTIONAL   \n",
       "\n",
       "       Total             Program_Description        Fund_Description  \\\n",
       "0  50471.810                    KINDERGARTEN            General Fund   \n",
       "1   3477.860   BUILDING IMPROVEMENT SERVICES                     NaN   \n",
       "2  62237.130           Instruction - Regular  General Purpose School   \n",
       "3     22.300  GENERAL MIDDLE/JUNIOR HIGH SCH                     NaN   \n",
       "4     54.166   GENERAL HIGH SCHOOL EDUCATION                     NaN   \n",
       "\n",
       "                          Text_1  \n",
       "0                            NaN  \n",
       "1  BUILDING IMPROVEMENT SERVICES  \n",
       "2                            NaN  \n",
       "3            REGULAR INSTRUCTION  \n",
       "4            REGULAR INSTRUCTION  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Function</th>\n",
       "      <th>Use</th>\n",
       "      <th>Sharing</th>\n",
       "      <th>Reporting</th>\n",
       "      <th>Student_Type</th>\n",
       "      <th>Position_Type</th>\n",
       "      <th>Object_Type</th>\n",
       "      <th>Pre_K</th>\n",
       "      <th>Operating_Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Sub_Object_Description</th>\n",
       "      <th>Location_Description</th>\n",
       "      <th>FTE</th>\n",
       "      <th>Function_Description</th>\n",
       "      <th>Facility_or_Department</th>\n",
       "      <th>Position_Extra</th>\n",
       "      <th>Total</th>\n",
       "      <th>Program_Description</th>\n",
       "      <th>Fund_Description</th>\n",
       "      <th>Text_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400272</th>\n",
       "      <td>109283</td>\n",
       "      <td>Professional Development</td>\n",
       "      <td>ISPD</td>\n",
       "      <td>Shared Services</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Instructional Coach</td>\n",
       "      <td>Other Compensation/Stipend</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>STAFF DEV AND INSTR MEDIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INST STAFF TRAINING SVCS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.620000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GENERAL FUND</td>\n",
       "      <td>STAFF DEV AND INSTR MEDIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400273</th>\n",
       "      <td>102430</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Base Salary/Compensation</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00431</td>\n",
       "      <td>TITLE II,D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROFESSIONAL-INSTRUCTIONAL</td>\n",
       "      <td>128.824985</td>\n",
       "      <td>INSTRUCTIONAL STAFF TRAINING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400274</th>\n",
       "      <td>413949</td>\n",
       "      <td>Parent &amp; Community Relations</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>Other</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARENT/TITLE I</td>\n",
       "      <td>4902.290000</td>\n",
       "      <td>Misc</td>\n",
       "      <td>Schoolwide Schools</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400275</th>\n",
       "      <td>433672</td>\n",
       "      <td>Library &amp; Media</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School on Central Budgets</td>\n",
       "      <td>Non-School</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Librarian</td>\n",
       "      <td>Benefits</td>\n",
       "      <td>NO_LABEL</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ED RESOURCE SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NON-PROJECT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OFFICE/ADMINISTRATIVE SUPPORT</td>\n",
       "      <td>4020.290000</td>\n",
       "      <td>MEDIA SUPPORT SERVICES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INSTRUCTIONAL STAFF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400276</th>\n",
       "      <td>415831</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>School Reported</td>\n",
       "      <td>School</td>\n",
       "      <td>Poverty</td>\n",
       "      <td>Substitute</td>\n",
       "      <td>Substitute Compensation</td>\n",
       "      <td>Non PreK</td>\n",
       "      <td>PreK-12 Operating</td>\n",
       "      <td>...</td>\n",
       "      <td>Inservice Substitute Teachers Grant Funded</td>\n",
       "      <td>School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Instruction</td>\n",
       "      <td>Instruction And Curriculum</td>\n",
       "      <td>CERTIFIED SUBSTITUTE</td>\n",
       "      <td>46.530000</td>\n",
       "      <td>Accelerated Education</td>\n",
       "      <td>\"Title  Part A Improving Basic Programs\"</td>\n",
       "      <td>MISCELLANEOUS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                      Function          Use  \\\n",
       "400272      109283      Professional Development         ISPD   \n",
       "400273      102430       Substitute Compensation  Instruction   \n",
       "400274      413949  Parent & Community Relations     NO_LABEL   \n",
       "400275      433672               Library & Media  Instruction   \n",
       "400276      415831       Substitute Compensation  Instruction   \n",
       "\n",
       "                          Sharing   Reporting Student_Type  \\\n",
       "400272            Shared Services  Non-School  Unspecified   \n",
       "400273            School Reported      School  Unspecified   \n",
       "400274            School Reported      School     NO_LABEL   \n",
       "400275  School on Central Budgets  Non-School  Unspecified   \n",
       "400276            School Reported      School      Poverty   \n",
       "\n",
       "              Position_Type                 Object_Type     Pre_K  \\\n",
       "400272  Instructional Coach  Other Compensation/Stipend  NO_LABEL   \n",
       "400273           Substitute    Base Salary/Compensation  NO_LABEL   \n",
       "400274                Other                    NO_LABEL  NO_LABEL   \n",
       "400275            Librarian                    Benefits  NO_LABEL   \n",
       "400276           Substitute     Substitute Compensation  Non PreK   \n",
       "\n",
       "         Operating_Status  ...                      Sub_Object_Description  \\\n",
       "400272  PreK-12 Operating  ...                                         NaN   \n",
       "400273  PreK-12 Operating  ...                                         NaN   \n",
       "400274  PreK-12 Operating  ...                                         NaN   \n",
       "400275  PreK-12 Operating  ...                                         NaN   \n",
       "400276  PreK-12 Operating  ...  Inservice Substitute Teachers Grant Funded   \n",
       "\n",
       "                  Location_Description      FTE  \\\n",
       "400272  STAFF DEV AND INSTR MEDIA           NaN   \n",
       "400273                             NaN  0.00431   \n",
       "400274                             NaN  1.00000   \n",
       "400275            ED RESOURCE SERVICES      NaN   \n",
       "400276                         School       NaN   \n",
       "\n",
       "                  Function_Description      Facility_or_Department  \\\n",
       "400272  INST STAFF TRAINING SVCS                               NaN   \n",
       "400273                      TITLE II,D                         NaN   \n",
       "400274                             NaN                         NaN   \n",
       "400275                     NON-PROJECT                         NaN   \n",
       "400276                     Instruction  Instruction And Curriculum   \n",
       "\n",
       "                       Position_Extra        Total  \\\n",
       "400272                            NaN    48.620000   \n",
       "400273     PROFESSIONAL-INSTRUCTIONAL   128.824985   \n",
       "400274                 PARENT/TITLE I  4902.290000   \n",
       "400275  OFFICE/ADMINISTRATIVE SUPPORT  4020.290000   \n",
       "400276           CERTIFIED SUBSTITUTE    46.530000   \n",
       "\n",
       "                 Program_Description  \\\n",
       "400272                           NaN   \n",
       "400273  INSTRUCTIONAL STAFF TRAINING   \n",
       "400274                          Misc   \n",
       "400275        MEDIA SUPPORT SERVICES   \n",
       "400276         Accelerated Education   \n",
       "\n",
       "                                Fund_Description  \\\n",
       "400272            GENERAL FUND                     \n",
       "400273                                       NaN   \n",
       "400274                        Schoolwide Schools   \n",
       "400275                                       NaN   \n",
       "400276  \"Title  Part A Improving Basic Programs\"   \n",
       "\n",
       "                                Text_1  \n",
       "400272  STAFF DEV AND INSTR MEDIA       \n",
       "400273             INSTRUCTIONAL STAFF  \n",
       "400274                             NaN  \n",
       "400275             INSTRUCTIONAL STAFF  \n",
       "400276                  MISCELLANEOUS   \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the histogram\n",
    "df['FTE'].dropna().hist()\n",
    "\n",
    "# Add title and labels\n",
    "plt.title('Distribution of %full-time \\n employee works')\n",
    "plt.xlabel('% of full-time')\n",
    "plt.ylabel('num employees')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "object     23\n",
       "float64     2\n",
       "int64       1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS=['Function',\n",
    " 'Use',\n",
    " 'Sharing',\n",
    " 'Reporting',\n",
    " 'Student_Type',\n",
    " 'Position_Type',\n",
    " 'Object_Type',\n",
    " 'Pre_K',\n",
    " 'Operating_Status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function            category\n",
      "Use                 category\n",
      "Sharing             category\n",
      "Reporting           category\n",
      "Student_Type        category\n",
      "Position_Type       category\n",
      "Object_Type         category\n",
      "Pre_K               category\n",
      "Operating_Status    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define the lambda function: categorize_label\n",
    "categorize_label = lambda x: x.astype('category')\n",
    "\n",
    "# Convert df[LABELS] to a categorical type\n",
    "df[LABELS] = df[LABELS].apply(categorize_label,axis=0)\n",
    "\n",
    "# Print the converted dtypes\n",
    "print(df[LABELS].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate number of unique values for each label: num_unique_labels\n",
    "num_unique_labels = df[LABELS].apply(pd.Series.nunique)\n",
    "\n",
    "# Plot number of unique values for each label\n",
    "num_unique_labels.plot(kind='bar')\n",
    "\n",
    "# Label the axes\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Number of unique values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we measure success?\n",
    "- Accuracy can be misleading when classes are imbalanced\n",
    "    - Legitmate email: 99%, Spam: 1%\n",
    "    - Model that never predicts spam will be 99% accurate!\n",
    "- Metric used in this problem: log loss\n",
    "    - Loss function\n",
    "    - Measure of error\n",
    "    - Want to minimize the error (unlike accuracy)\n",
    "- Log loss binary classification\n",
    "$$ log loss = -\\frac{1}{N} \\sum^{N}_{i=1}(y_i \\log(p_i)) + (1- y_i)\\log(1-p_i)) $$\n",
    "    - Actual value: $y: {1=\\text{yes}, 0=\\text{no}}$\n",
    "    - Prediction (probability that the value is 1): $p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_log_loss(predicted, actual, eps=1e-14):\n",
    "    \"\"\"Compute the logarithmic loss between predicted and\n",
    "       actual when these are 1D arrays\n",
    " \n",
    "       :param predicted: The predicted probabilties as floats between 0-1\n",
    "       :param actual: The actual binary labels. Either 0 or 1\n",
    "       :param eps (optional): log(0) is inf, so we need to offset our\n",
    "                               predicted values slightly by eps from 0 or 1.\n",
    "    \"\"\"\n",
    "    predicted = np.clip(predicted, eps, 1-eps)\n",
    "    loss = -1 * np.mean(actual * np.log(predicted) + (1 - actual) * np.log(1 - predicted))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_confident = np.array([0.95, 0.95, 0.95, 0.95, 0.95, 0.05, 0.05, 0.05, 0.05, 0.05])\n",
    "correct_not_confident = np.array([0.65, 0.65, 0.65, 0.65, 0.65, 0.35, 0.35, 0.35, 0.35, 0.35])\n",
    "wrong_not_confident = np.array([0.35, 0.35, 0.35, 0.35, 0.35, 0.65, 0.65, 0.65, 0.65, 0.65])\n",
    "wrong_confident = np.array([0.05, 0.05, 0.05, 0.05, 0.05, 0.95, 0.95, 0.95, 0.95, 0.95])\n",
    "actual_labels = np.array([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss, correct and confident: 0.05129329438755058\n",
      "Log loss, correct and not confident: 0.4307829160924542\n",
      "Log loss, wrong and not confident: 1.049822124498678\n",
      "Log loss, wrong and confident: 2.9957322735539904\n",
      "Log loss, actual labels: 9.99200722162646e-15\n"
     ]
    }
   ],
   "source": [
    "# Compute and print log loss for 1st case\n",
    "correct_confident_loss = compute_log_loss(correct_confident, actual_labels)\n",
    "print(\"Log loss, correct and confident: {}\".format(correct_confident_loss)) \n",
    "\n",
    "# Compute log loss for 2nd case\n",
    "correct_not_confident_loss = compute_log_loss(correct_not_confident, actual_labels)\n",
    "print(\"Log loss, correct and not confident: {}\".format(correct_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 3rd case\n",
    "wrong_not_confident_loss = compute_log_loss(wrong_not_confident, actual_labels)\n",
    "print(\"Log loss, wrong and not confident: {}\".format(wrong_not_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for 4th case\n",
    "wrong_confident_loss = compute_log_loss(wrong_confident, actual_labels)\n",
    "print(\"Log loss, wrong and confident: {}\".format(wrong_confident_loss)) \n",
    "\n",
    "# Compute and print log loss for actual labels\n",
    "actual_labels_loss = compute_log_loss(actual_labels, actual_labels)\n",
    "print(\"Log loss, actual labels: {}\".format(actual_labels_loss)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a train-test split in scikit-learn\n",
    "Alright, you've been patient and awesome. It's finally time to start training models!\n",
    "\n",
    "The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_count examples of each label appear in each split: **multilabel_train_test_split**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import warn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multilabel_sample(y, size=1000, min_count=5, seed=None):\n",
    "    \"\"\" Takes a matrix of binary labels `y` and returns\n",
    "        the indices for a sample of size `size` if\n",
    "        `size` > 1 or `size` * len(y) if size =< 1.\n",
    "        The sample is guaranteed to have > `min_count` of\n",
    "        each label.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (np.unique(y).astype(int) != np.array([0, 1])).any():\n",
    "            raise ValueError()\n",
    "    except (TypeError, ValueError):\n",
    "        raise ValueError('multilabel_sample only works with binary indicator matrices')\n",
    "\n",
    "    if (y.sum(axis=0) < min_count).any():\n",
    "        raise ValueError('Some classes do not have enough examples. Change min_count if necessary.')\n",
    "\n",
    "    if size <= 1:\n",
    "        size = np.floor(y.shape[0] * size)\n",
    "\n",
    "    if y.shape[1] * min_count > size:\n",
    "        msg = \"Size less than number of columns * min_count, returning {} items instead of {}.\"\n",
    "        warn(msg.format(y.shape[1] * min_count, size))\n",
    "        size = y.shape[1] * min_count\n",
    "\n",
    "    rng = np.random.RandomState(seed if seed is not None else np.random.randint(1))\n",
    "\n",
    "    if isinstance(y, pd.DataFrame):\n",
    "        choices = y.index\n",
    "        y = y.values\n",
    "    else:\n",
    "        choices = np.arange(y.shape[0])\n",
    "\n",
    "    sample_idxs = np.array([], dtype=choices.dtype)\n",
    "\n",
    "    # first, guarantee > min_count of each label\n",
    "    for j in range(y.shape[1]):\n",
    "        label_choices = choices[y[:, j] == 1]\n",
    "        label_idxs_sampled = rng.choice(label_choices, size=min_count, replace=False)\n",
    "        sample_idxs = np.concatenate([label_idxs_sampled, sample_idxs])\n",
    "\n",
    "    sample_idxs = np.unique(sample_idxs)\n",
    "\n",
    "    # now that we have at least min_count of each, we can just random sample\n",
    "    sample_count = int(size - sample_idxs.shape[0])\n",
    "\n",
    "    # get sample_count indices from remaining choices\n",
    "    remaining_choices = np.setdiff1d(choices, sample_idxs)\n",
    "    remaining_sampled = rng.choice(remaining_choices,\n",
    "                                   size=sample_count,\n",
    "                                   replace=False)\n",
    "\n",
    "    return np.concatenate([sample_idxs, remaining_sampled])\n",
    "\n",
    "\n",
    "def multilabel_sample_dataframe(df, labels, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a dataframe `df` and returns a sample of size `size` where all\n",
    "        classes in the binary matrix `labels` are represented at\n",
    "        least `min_count` times.\n",
    "    \"\"\"\n",
    "    idxs = multilabel_sample(labels, size=size, min_count=min_count, seed=seed)\n",
    "    return df.loc[idxs]\n",
    "\n",
    "\n",
    "def multilabel_train_test_split(X, Y, size, min_count=5, seed=None):\n",
    "    \"\"\" Takes a features matrix `X` and a label matrix `Y` and\n",
    "        returns (X_train, X_test, Y_train, Y_test) where all\n",
    "        classes in Y are represented at least `min_count` times.\n",
    "    \"\"\"\n",
    "    index = Y.index if isinstance(Y, pd.DataFrame) else np.arange(Y.shape[0])\n",
    "\n",
    "    test_set_idxs = multilabel_sample(Y, size=size, min_count=min_count, seed=seed)\n",
    "    train_set_idxs = np.setdiff1d(index, test_set_idxs)\n",
    "\n",
    "    test_set_mask = index.isin(test_set_idxs)\n",
    "    train_set_mask = ~test_set_mask\n",
    "\n",
    "    return (X[train_set_mask], X[test_set_mask], Y[train_set_mask], Y[test_set_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_COLUMNS = ['FTE', 'Total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 0 to 400276\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   FTE     320222 non-null  float64\n",
      " 1   Total   320222 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 7.3 MB\n",
      "None\n",
      "\n",
      "X_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 4 to 400274\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   FTE     80055 non-null  float64\n",
      " 1   Total   80055 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 1.8 MB\n",
      "None\n",
      "\n",
      "y_train info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 320222 entries, 0 to 400276\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 34.2 MB\n",
      "None\n",
      "\n",
      "y_test info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 80055 entries, 4 to 400274\n",
      "Columns: 104 entries, Function_Aides Compensation to Operating_Status_PreK-12 Operating\n",
      "dtypes: uint8(104)\n",
      "memory usage: 8.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Create the new DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test =multilabel_train_test_split(\n",
    "                numeric_data_only,\n",
    "                label_dummies,\n",
    "                size=0.2, \n",
    "                seed=123)\n",
    "\n",
    "# Print the info\n",
    "print(\"X_train info:\")\n",
    "print(X_train.info())\n",
    "print(\"\\nX_test info:\")  \n",
    "print(X_test.info())\n",
    "print(\"\\ny_train info:\")  \n",
    "print(y_train.info())\n",
    "print(\"\\ny_test info:\")  \n",
    "print(y_test.info()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create the DataFrame: numeric_data_only\n",
    "numeric_data_only = df[NUMERIC_COLUMNS].fillna(-1000)\n",
    "\n",
    "# Get labels and convert to dummy variables: label_dummies\n",
    "label_dummies = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(numeric_data_only,\n",
    "                                                               label_dummies,\n",
    "                                                               size=0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {}\".format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ok! The good news is that your workflow didn't cause any errors. The bad news is that your model scored the lowest possible accuracy: 0.0! But hey, you just threw away ALL of the text data in the budget. Later, you won't. Before you add the text data, let's see how the model does when scored by log loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use your model to predict values on holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: clf\n",
    "clf = OneVsRestClassifier(LogisticRegression())\n",
    "\n",
    "# Fit it to the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Load the holdout data: holdout\n",
    "holdout = pd.read_csv('HoldoutData.csv', index_col=0)\n",
    "\n",
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out your results to a csv for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_submission(pred_path='PATH_TO_PREDICTIONS', holdout_path='PATH_TO_HOLDOUT_LABELS'):\n",
    "    # this happens on the backend to get the score   \n",
    "    holdout_labels = pd.get_dummies(pd.read_csv(holdout_path, index_col=0).apply(lambda x: x.astype('category'), axis=0))\n",
    "    preds = pd.read_csv(pred_path, index_col=0)\n",
    "    # make sure that format is correct\\n    \n",
    "    assert (preds.columns == holdout_labels.columns).all()\n",
    "    assert (preds.index == holdout_labels.index).all()  \n",
    "    return _multi_multi_log_loss(preds.values, holdout_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions: predictions\n",
    "predictions = clf.predict_proba(holdout[NUMERIC_COLUMNS].fillna(-1000))\n",
    "\n",
    "# Format predictions in DataFrame: prediction_df\n",
    "prediction_df = pd.DataFrame(columns=pd.get_dummies(df[LABELS]).columns,\n",
    "                             index=holdout.index,\n",
    "                             data=predictions)\n",
    "\n",
    "\n",
    "# Save prediction_df to csv\n",
    "prediction_df.to_csv('predictions.csv')\n",
    "\n",
    "# Submit the predictions for scoring: score\n",
    "score = score_submission(pred_path='predictions.csv')\n",
    "\n",
    "# Print score\n",
    "print('Your model, trained with numeric data only, yields logloss score: {}'.format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a bag-of-words in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Fill missing values in df.Position_Extra\n",
    "df.Position_Extra.fillna('',inplace=True)\n",
    "\n",
    "# Instantiate the CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit to the data\n",
    "vec_alphanumeric.fit(df.Position_Extra)\n",
    "\n",
    "# Print the number of tokens and first 15 tokens\n",
    "msg = \"There are {} tokens in Position_Extra if we split on non-alpha numeric\"\n",
    "print(msg.format(len(vec_alphanumeric.get_feature_names())))\n",
    "print(vec_alphanumeric.get_feature_names()[:15])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 123 tokens in Position_Extra if we split on non-alpha numeric\n",
    "    ['1st', '2nd', '3rd', 'a', 'ab', 'additional', 'adm', 'administrative', 'and', 'any', 'art', 'assessment', 'assistant', 'asst', 'athletic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining text columns for tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define combine_text_columns()\n",
    "def combine_text_columns(data_frame, to_drop=NUMERIC_COLUMNS + LABELS):\n",
    "    \"\"\" converts all text in each row of data_frame to single vector \"\"\"\n",
    "    \n",
    "    # Drop non-text columns that are in the df\n",
    "    to_drop = set(to_drop) & set(data_frame.columns.tolist())\n",
    "    text_data = data_frame.drop(to_drop, axis=1)\n",
    "    \n",
    "    # Replace nans with blanks\n",
    "    text_data.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Join all text items in a row that have a space in between\n",
    "    return text_data.apply(lambda x: \" \".join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the basic token pattern\n",
    "TOKENS_BASIC = '\\\\S+(?=\\\\s+)'\n",
    "\n",
    "# Create the alphanumeric token pattern\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate basic CountVectorizer: vec_basic\n",
    "vec_basic = CountVectorizer(token_pattern=TOKENS_BASIC)\n",
    "\n",
    "# Instantiate alphanumeric CountVectorizer: vec_alphanumeric\n",
    "vec_alphanumeric = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(df)\n",
    "\n",
    "# Fit and transform vec_basic\n",
    "vec_basic.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_basic\n",
    "print(\"There are {} tokens in the dataset\".format(len(vec_basic.get_feature_names())))\n",
    "\n",
    "# Fit and transform vec_alphanumeric\n",
    "vec_alphanumeric.fit_transform(text_vector)\n",
    "\n",
    "# Print number of tokens of vec_alphanumeric\n",
    "print(\"There are {} alpha-numeric tokens in the dataset\".format(len(vec_alphanumeric.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines, feature &text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import other necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Split and select numeric data only, no nans \n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - numeric, no nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on sample data - numeric, no nans:  0.62"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Imputer object\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# Create training and test sets using only numeric data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Insantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('imp', Imputer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pl.fit(X_train,y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test,y_test)\n",
    "print(\"\\nAccuracy on sample data - all numeric, incl nans: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Accuracy on sample data - all numeric, incl nans:  0.636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Split out only the text data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df['text'],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=456)\n",
    "\n",
    "# Instantiate Pipeline object: pl\n",
    "pl = Pipeline([\n",
    "        ('vec', CountVectorizer()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - just text data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy on sample data - just text data:  0.808"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Obtain the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(lambda x: x['text'], validate=False)\n",
    "\n",
    "# Obtain the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[['numeric', 'with_missing']], validate=False)\n",
    "\n",
    "# Fit and transform the text data: just_text_data\n",
    "just_text_data = get_text_data.fit_transform(sample_df)\n",
    "\n",
    "# Fit and transform the numeric data: just_numeric_data\n",
    "just_numeric_data = get_numeric_data.fit_transform(sample_df)\n",
    "\n",
    "# Print head to check results\n",
    "print('Text Data')\n",
    "print(just_text_data.head())\n",
    "print('\\nNumeric Data')\n",
    "print(just_numeric_data.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Text Data\n",
    "0           \n",
    "1        foo\n",
    "2    foo bar\n",
    "3           \n",
    "4    foo bar\n",
    "Name: text, dtype: object\n",
    "\n",
    "Numeric Data\n",
    "     numeric  with_missing\n",
    "0 -10.856306      4.433240\n",
    "1   9.973454      4.310229\n",
    "2   2.829785      2.469828\n",
    "3 -15.062947      2.852981\n",
    "4  -5.786003      1.826475"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple types of processing: FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FeatureUnion\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Split using ALL data in sample_df\n",
    "X_train, X_test, y_train, y_test = train_test_split(sample_df[['numeric', 'with_missing', 'text']],\n",
    "                                                    pd.get_dummies(sample_df['label']), \n",
    "                                                    random_state=22)\n",
    "\n",
    "# Create a FeatureUnion with nested pipeline: process_and_join_features\n",
    "process_and_join_features = FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )\n",
    "\n",
    "# Instantiate nested pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', process_and_join_features),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "\n",
    "# Fit pl to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on sample data - all data: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Accuracy on sample data - all data:  0.928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using FunctionTransformer on the main dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_LABELS=['Object_Description',\n",
    " 'Text_2',\n",
    " 'SubFund_Description',\n",
    " 'Job_Title_Description',\n",
    " 'Text_3',\n",
    " 'Text_4',\n",
    " 'Sub_Object_Description',\n",
    " 'Location_Description',\n",
    " 'FTE',\n",
    " 'Function_Description',\n",
    " 'Facility_or_Department',\n",
    " 'Position_Extra',\n",
    " 'Total',\n",
    " 'Program_Description',\n",
    " 'Fund_Description',\n",
    " 'Text_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import FunctionTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Get the dummy encoding of the labels\n",
    "dummy_labels = pd.get_dummies(df[LABELS])\n",
    "\n",
    "# Get the columns that are features in the original df\n",
    "NON_LABELS = [c for c in df.columns if c not in LABELS]\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = multilabel_train_test_split(df[NON_LABELS],\n",
    "                                                               dummy_labels,\n",
    "                                                               0.2, \n",
    "                                                               seed=123)\n",
    "\n",
    "# Preprocess the text data: get_text_data\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "\n",
    "# Preprocess the numeric data: get_numeric_data\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a model to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a different class of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import random forest classifer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Edit model step in pipeline\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can you adjust the model or parameters to improve accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Add model step to pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer())\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('clf', RandomForestClassifier(n_estimators=15))\n",
    "    ])\n",
    "\n",
    "# Fit to the training data\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# Compute and print accuracy\n",
    "accuracy = pl.score(X_test, y_test)\n",
    "print(\"\\nAccuracy on budget dataset: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding what's a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create the text vector\n",
    "text_vector = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate the CountVectorizer: text_features\n",
    "text_features = CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit text_features to the text vector\n",
    "text_features.fit(text_vector)\n",
    "\n",
    "# Print the first 10 tokens\n",
    "print(text_features.get_feature_names()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N-gram range in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Import other preprocessing modules\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "# Select 300 best features\n",
    "chi_k = 300\n",
    "\n",
    "# Import functional utilities\n",
    "from sklearn.preprocessing import FunctionTransformer, MaxAbsScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# Perform preprocessing\n",
    "get_text_data = FunctionTransformer(combine_text_columns, validate=False)\n",
    "get_numeric_data = FunctionTransformer(lambda x: x[NUMERIC_COLUMNS], validate=False)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)'\n",
    "\n",
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement interaction modeling in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class SparseInteractions(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, degree=2, feature_name_separator=\"_\"):\n",
    "        self.degree = degree\n",
    "        self.feature_name_separator = feature_name_separator\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not sparse.isspmatrix_csc(X):\n",
    "            X = sparse.csc_matrix(X)\n",
    "\n",
    "        if hasattr(X, \"columns\"):\n",
    "            self.orig_col_names = X.columns\n",
    "        else:\n",
    "            self.orig_col_names = np.array([str(i) for i in range(X.shape[1])])\n",
    "\n",
    "        spi = self._create_sparse_interactions(X)\n",
    "        return spi\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return self.feature_names\n",
    "\n",
    "    def _create_sparse_interactions(self, X):\n",
    "        out_mat = []\n",
    "        self.feature_names = self.orig_col_names.tolist()\n",
    "\n",
    "        for sub_degree in range(2, self.degree + 1):\n",
    "            for col_ixs in combinations(range(X.shape[1]), sub_degree):\n",
    "                # add name for new column\n",
    "                name = self.feature_name_separator.join(self.orig_col_names[list(col_ixs)])\n",
    "                self.feature_names.append(name)\n",
    "\n",
    "                # get column multiplications value\n",
    "                out = X[:, col_ixs[0]]\n",
    "                for j in col_ixs[1:]:\n",
    "                    out = out.multiply(X[:, j])\n",
    "\n",
    "                out_mat.append(out)\n",
    "\n",
    "        return sparse.hstack([X] + out_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', CountVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                   ngram_range=(1, 2))),  \n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing the hashing trick in scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Get text data: text_data\n",
    "text_data = combine_text_columns(X_train)\n",
    "\n",
    "# Create the token pattern: TOKENS_ALPHANUMERIC\n",
    "TOKENS_ALPHANUMERIC = '[A-Za-z0-9]+(?=\\\\s+)' \n",
    "\n",
    "# Instantiate the HashingVectorizer: hashing_vec\n",
    "hashing_vec = HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC)\n",
    "\n",
    "# Fit and transform the Hashing Vectorizer\n",
    "hashed_text = hashing_vec.fit_transform(text_data)\n",
    "\n",
    "# Create DataFrame and print the head\n",
    "hashed_df = pd.DataFrame(hashed_text.data)\n",
    "print(hashed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the hashing vectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "# Instantiate the winning model pipeline: pl\n",
    "pl = Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "            transformer_list = [\n",
    "                ('numeric_features', Pipeline([\n",
    "                    ('selector', get_numeric_data),\n",
    "                    ('imputer', Imputer())\n",
    "                ])),\n",
    "                ('text_features', Pipeline([\n",
    "                    ('selector', get_text_data),\n",
    "                    ('vectorizer', HashingVectorizer(token_pattern=TOKENS_ALPHANUMERIC,\n",
    "                                                     non_negative=True, norm=None, binary=False,\n",
    "                                                     ngram_range=(1,2))),\n",
    "                    ('dim_red', SelectKBest(chi2, chi_k))\n",
    "                ]))\n",
    "             ]\n",
    "        )),\n",
    "        ('int', SparseInteractions(degree=2)),\n",
    "        ('scale', MaxAbsScaler()),\n",
    "        ('clf', OneVsRestClassifier(LogisticRegression()))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
